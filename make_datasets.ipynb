{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1d31f54",
   "metadata": {},
   "source": [
    "# Notebook for preprocessing Wikipedia (Czech) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import sys\n",
    "from datasets import load_dataset, Dataset\n",
    "from tpp_ttstool import TppTtstool\n",
    "from phonemize import phonemize\n",
    "from pebble import ProcessPool\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "# # Set path to compatible transformers 4.33.3 library\n",
    "# sys.path.insert(0, '/storage/plzen4-ntis/home/jmatouse/.local/transformers-4.33.3/lib/python3.10/site-packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9747a-987b-4c2c-a7c0-0c24b79b0daa",
   "metadata": {},
   "source": [
    "## Papermill options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341058b9-3740-4bab-9e45-a309fefa6eb8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "inp_text_file = '../BERT_cs/WIKI_C4Cleaned.sentences1k.norm_part0.txt'\n",
    "# inp_text_file = 'test_preprocess.txt'\n",
    "out_dataset_folder = 'datasets/cz-wikipedia.processed'\n",
    "tokenizer_path = 'fav-kky/FERNET-C5'\n",
    "punctuation = '.,;:-?!…' # !!! TODO: definovat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd70412-89e9-4a20-8724-6b0b2b3e6545",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bbd72d-f9ba-485c-ae33-53298eb8594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CPUS = int(os.environ[\"PBS_NUM_PPN\"])\n",
    "TTSTOOL_BIN = \"tts_tool/tts_tool\"\n",
    "TTSTOOL_DATA = \"tts_tool/data/frontend_ph-redu_pauses.json\"\n",
    "NUM_SHARDS = NUM_CPUS * 4\n",
    "\n",
    "print(f\"> Number of CPUs:   {NUM_CPUS}\")\n",
    "print(f\"> Number of shards: {NUM_SHARDS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24723b2f-7b88-40c9-8dfb-fdebe516a9b6",
   "metadata": {},
   "source": [
    "### Pomocné funkce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98df38ba-eb47-4af1-ac27-a5a9f4fc00cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to safely phonemize a shard\n",
    "def safe_phonemize_shard(shard):\n",
    "    global phonemizer, punctuation\n",
    "    processed = []\n",
    "    for ex in shard:\n",
    "        try:\n",
    "            # Attempt to phonemize the text\n",
    "            phonemized = phonemize(ex['text'], phonemizer, tokenizer, punctuation)\n",
    "            processed.append(phonemized)\n",
    "        except Exception as e:\n",
    "            # Log the problematic entry and the exception details\n",
    "            print(f\"Exception encountered for entry: {ex['text']}\")\n",
    "            print(f\"Error details: {e}\")\n",
    "    return processed\n",
    "\n",
    "# Function to process dataset shards in parallel\n",
    "def process_dataset_shards_in_parallel(dataset, num_shards, num_workers):\n",
    "    # Split dataset into shards\n",
    "    shards = [dataset.shard(num_shards, i, contiguous=True) for i in range(num_shards)]\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # Process each shard in parallel\n",
    "        results = executor.map(safe_phonemize_shard, shards)\n",
    "    # Combine all processed shards into a single list\n",
    "    combined_results = [item for shard in results for item in shard]\n",
    "    return combined_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eb8ed4",
   "metadata": {},
   "source": [
    "### Initialize phonemizer and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d54fe-25d4-41d5-be60-05a4f9f05530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup TPP with path to tts_tool binary and data\n",
    "phonemizer = TppTtstool('cz', tts_tool_bin=TTSTOOL_BIN, tts_tool_data=TTSTOOL_DATA, punct=punctuation)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb25417",
   "metadata": {},
   "source": [
    "### Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e5ae16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load dataset from local text file\n",
    "dataset = load_dataset('text', data_files=inp_text_file)['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2127f3-2e66-410c-9f75-2b0978c24d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the dataset shards in parallel\n",
    "processed_results = process_dataset_shards_in_parallel(dataset, NUM_SHARDS, num_workers=NUM_CPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e0019c-95ef-4ce9-a481-9e4339829b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the processed results back to a Hugging Face dataset\n",
    "processed_dataset = Dataset.from_list(processed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e06de32-f6a2-4bab-b602-46fce44c8573",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset.save_to_disk(out_dataset_folder)\n",
    "print(f\"Dataset saved to {out_dataset_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bca6c8-1e49-4593-b5eb-2dc65721e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Original sentences:   {len(dataset)}')\n",
    "print(f'Phonemized sentences: {len(processed_dataset)}')\n",
    "print(f'Used %:               {len(processed_dataset)/len(dataset):.2%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
